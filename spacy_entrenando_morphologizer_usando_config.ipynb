{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c30f864",
   "metadata": {},
   "source": [
    "# Creando Datos para Entrenamiento y Entrenando Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b0916",
   "metadata": {},
   "source": [
    "**Por qué actualizar un modelo?**\n",
    "\n",
    "- Los modelos estadísticos hacen predicciones basadas en los ejemplos con los que fueron entrenados.\n",
    "- Un modelo será más preciso con ejemplos de su dominio.\n",
    "- Para predecir categorías específicas de su problema, el modelo debe aprender sobre ellas.\n",
    "- Esencial para *text classification*, muy útil para *entity recognition* y un poco menos crítico para *tagging* y *parsing*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ed568",
   "metadata": {},
   "source": [
    "**Cómo funciona el entrenamiento?**\n",
    "\n",
    "Si no inicializamos con una pipeline entrenada:\n",
    "\n",
    "1. **Inicializamos** el modelo con pesos aleatorios.\n",
    "2. **Predecimos** un batch de ejemplos con los pesos actuales, usando `nlp.update`.\n",
    "3. **Compara** la predicción con las labels verdaderas y **calcula** cómo cambiar los pesos para mejorar las predicciones.\n",
    "4. **Actualización** de los pesos.\n",
    "5. Paso 2. spaCy continua llamando `nlp.update` para cada batch de exemplos hasta que el modelo deje de mejorar.\n",
    "\n",
    "Después del entrenamiento, podemos guardar un modelo actualizado y usarlo en nuestra aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ba1f3",
   "metadata": {},
   "source": [
    "## Datos de Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402fd68",
   "metadata": {},
   "source": [
    "* Los **datos de entrenamiento** son los ejemplos con los que queremos actualizar el modelo. El **texto** debe ser similar a lo que el modelo verá en el runtime y el **label** es lo que el modelo debe predecir (categoría o un entity span y su tipo).\n",
    "\n",
    "* Los datos de entrenamiento:\n",
    "  * Suelen ser creados por humanos que asignan etiquetas a los textos. Herramientas de anotación: `Prodigy`, `Rubrix`, etc. \n",
    "  * Esto es mucho trabajo, pero puede ser semiautomatizado, por ejemplo, usando la clase `Matcher`.\n",
    "\n",
    "* Dividimos los datos en entrenamiento y prueba, en formatos `.spacy`.\n",
    "  * A partir de objetos `DocBin`.\n",
    "  * En algunos casos, es posible que ya tenga datos en un formato común, por ejemplo, `.conll`, `.conllu` o `.iob`. El comando `convert`de spaCy convierte automáticamente estos archivos al formato binario de spaCy:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaed22f5",
   "metadata": {},
   "source": [
    "$ python -m spacy convert ./train.gold.conll ./corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07689b1f",
   "metadata": {},
   "source": [
    "* `spacy convert`: El comando para correr\n",
    "* `./train.gold.conll`: Ruta al archivo\n",
    "* `./corpus`: Carpeta donde será colocado el archivo `.spacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07afcce",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e67c5",
   "metadata": {},
   "source": [
    "**Qué es el config.cfg?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f911a3",
   "metadata": {},
   "source": [
    "* `config.cfg` es la \"única fuente de la verdad\" para todos los settings.\n",
    "* Define cómo inicializar el objeto `nlp`, qué componentes de pipeline adicionar y cómo deben configurarse sus implementaciones de modelos internos. También incluye todas las configuraciones para el proceso de entrenamiento y cómo cargar los datos, incluidos los hiperparámetros.\n",
    "* Ayudan a la reproducibilidad de tu entrenamiento.\n",
    "* El config es agrupado en secciones y las secciones anidadas son definidas usando un punto. Por ejemplo: `[components.ner.model]` define la configuración para la implementación del modelo del named entity recognizer.\n",
    "* Los archivos config también pueden hacer referencia a funciones de Python mediante la notación `@`. Por ejemplo, el tokenizador define una función de tokenizador registrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c66d22",
   "metadata": {},
   "source": [
    "**Generando un config**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2e631",
   "metadata": {},
   "source": [
    "* spaCy puede generar un archivo config predeterminado para ti.\n",
    "* El widget `quickstart` le permite generar una configuración de forma interactiva seleccionando el idioma y los componentes de pipeline que necesita, así como configuraciones opcionales de hardware y de optimización.\n",
    "* Alternativamente, también puede usar el comando `init config` de spaCy:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6b3a2fd",
   "metadata": {},
   "source": [
    "$ python -m spacy init config ./config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48becc1a",
   "metadata": {},
   "source": [
    "* `init config`: el comando para correr\n",
    "* `config.cfg`: la trayectoria de salida para el config generado.\n",
    "* `--lang`: la clase de lenguaje que debe ser usado por del pipeline, por ejemplo: `es` para Español.\n",
    "* `--pipeline`: los nombres de los componentes del pipeline separados por comas para incluir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714d1de",
   "metadata": {},
   "source": [
    "**Entrenando un pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf07bc1",
   "metadata": {},
   "source": [
    "* Para entrenar un pipeline, todo lo que necesitas es el archivo `config.cfg` y los datos de entrenamiento y teste (archivos `.spacy`).\n",
    "* La configuración `config` puede ser sobreescrita en la línea de comando."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b70809c",
   "metadata": {},
   "source": [
    "$ python -m spacy train ./config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e3129",
   "metadata": {},
   "source": [
    "* `train`: el comando para correr\n",
    "* `config.cfg`: la trayectoria al archivo config\n",
    "* `--output`: la trayectoria a la carpeta de salida para salvar el pipeline entrenado.\n",
    "* `--paths.train`: anula con ruta a los datos de entrenamiento\n",
    "* `--paths.dev`: anula con ruta a los datos de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a8ad0",
   "metadata": {},
   "source": [
    "* Cada paso sobre los datos durante el entrenamiento es llamado una \"época\".\n",
    "* Dentro de cada época, spaCy genera los scores de precisión a cada 200 ejemplos (puedes cambiar la frecuencia en el config).\n",
    "* Cada línea muestra la pérdida (loss) y precisión calculada en este punto durante el entrenamiento.\n",
    "* La puntuación más interesante a tener en cuenta es la puntuación combinada de la última columna. Refleja la precisión con la que su modelo predijo las respuestas correctas en los datos de evaluación.\n",
    "* El entrenamiento se ejecuta hasta que el modelo deja de mejorar y termina automáticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d02bc",
   "metadata": {},
   "source": [
    "**Cargando un pipeline entrenado**\n",
    "\n",
    "* El último pipeline entrenado (`model-last`) y el pipeline con el mejor score (`model-best`) son salvados en el directorio de salida.\n",
    "* Puedes cargar tu pipeline entrenada utilizando `spacy.load`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3f397",
   "metadata": {},
   "source": [
    "**Empaquetando tu pipeline**\n",
    "\n",
    "* `spacy package` crea un paquete de Python instalable que contiene tu pipeline. Después de la instalación, puedes cargar tu pipeline usando su nombre. spaCy automáticamente adiciona el código del lenguaje al nombre (`my_pipeline` pasará a ser `es_my_pipeline`).\n",
    "* Fácil de versionar e desplegar (deploy)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "50dfea9b",
   "metadata": {},
   "source": [
    "$ python -m spacy package /path/to/output/model-best ./packages --name my_pipeline --version 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca62695",
   "metadata": {},
   "source": [
    "* `/path/to/output/model-best`: Trayectoria de tu pipeline exportado\n",
    "* `/packages`: Carpeta de salida.\n",
    "* `my_pipeline`: Nombre opcional.\n",
    "* `1.0.0`: Versión opcional."
   ]
  },
  {
   "cell_type": "raw",
   "id": "03f5bc97",
   "metadata": {},
   "source": [
    "$ cd ./packages/es_my_pipeline-1.0.0\n",
    "$ pip install dist/es_my_pipeline-1.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6e62ef9",
   "metadata": {},
   "source": [
    "nlp = spacy.load(\"es_my_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40897a",
   "metadata": {},
   "source": [
    "# Creando un Modelo Personalizado para PoS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf61e3",
   "metadata": {},
   "source": [
    "Utilizaremos el arquivo conllu de Petrolês: http://petroles.ica.ele.puc-rio.br/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"model_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dff5a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jessi/Documentos/Data_Science/spacy/model_pos\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf34796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (66 documents): corpus/train.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy convert ./train.conllu ./corpus -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391d593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (17 documents): corpus/dev.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy convert ./dev.conllu ./corpus -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabf305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: pt\n",
      "- Pipeline: morphologizer\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config ./config.cfg --lang pt --pipeline morphologizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff30af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\r\n",
      "train = null\r\n",
      "dev = null\r\n",
      "vectors = null\r\n",
      "init_tok2vec = null\r\n",
      "\r\n",
      "[system]\r\n",
      "gpu_allocator = null\r\n",
      "seed = 0\r\n",
      "\r\n",
      "[nlp]\r\n",
      "lang = \"pt\"\r\n",
      "pipeline = [\"tok2vec\",\"morphologizer\"]\r\n",
      "batch_size = 1000\r\n",
      "disabled = []\r\n",
      "before_creation = null\r\n",
      "after_creation = null\r\n",
      "after_pipeline_creation = null\r\n",
      "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\r\n",
      "\r\n",
      "[components]\r\n",
      "\r\n",
      "[components.morphologizer]\r\n",
      "factory = \"morphologizer\"\r\n",
      "\r\n",
      "[components.morphologizer.model]\r\n",
      "@architectures = \"spacy.Tagger.v1\"\r\n",
      "nO = null\r\n",
      "\r\n",
      "[components.morphologizer.model.tok2vec]\r\n",
      "@architectures = \"spacy.Tok2VecListener.v1\"\r\n",
      "width = ${components.tok2vec.model.encode.width}\r\n",
      "upstream = \"*\"\r\n",
      "\r\n",
      "[components.tok2vec]\r\n",
      "factory = \"tok2vec\"\r\n",
      "\r\n",
      "[components.tok2vec.model]\r\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\r\n",
      "\r\n",
      "[components.tok2vec.model.embed]\r\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\r\n",
      "width = ${components.tok2vec.model.encode.width}\r\n",
      "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\r\n",
      "rows = [5000,2500,2500,2500]\r\n",
      "include_static_vectors = false\r\n",
      "\r\n",
      "[components.tok2vec.model.encode]\r\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\r\n",
      "width = 96\r\n",
      "depth = 4\r\n",
      "window_size = 1\r\n",
      "maxout_pieces = 3\r\n",
      "\r\n",
      "[corpora]\r\n",
      "\r\n",
      "[corpora.dev]\r\n",
      "@readers = \"spacy.Corpus.v1\"\r\n",
      "path = ${paths.dev}\r\n",
      "max_length = 0\r\n",
      "gold_preproc = false\r\n",
      "limit = 0\r\n",
      "augmenter = null\r\n",
      "\r\n",
      "[corpora.train]\r\n",
      "@readers = \"spacy.Corpus.v1\"\r\n",
      "path = ${paths.train}\r\n",
      "max_length = 0\r\n",
      "gold_preproc = false\r\n",
      "limit = 0\r\n",
      "augmenter = null\r\n",
      "\r\n",
      "[training]\r\n",
      "dev_corpus = \"corpora.dev\"\r\n",
      "train_corpus = \"corpora.train\"\r\n",
      "seed = ${system.seed}\r\n",
      "gpu_allocator = ${system.gpu_allocator}\r\n",
      "dropout = 0.1\r\n",
      "accumulate_gradient = 1\r\n",
      "patience = 1600\r\n",
      "max_epochs = 0\r\n",
      "max_steps = 20000\r\n",
      "eval_frequency = 200\r\n",
      "frozen_components = []\r\n",
      "annotating_components = []\r\n",
      "before_to_disk = null\r\n",
      "\r\n",
      "[training.batcher]\r\n",
      "@batchers = \"spacy.batch_by_words.v1\"\r\n",
      "discard_oversize = false\r\n",
      "tolerance = 0.2\r\n",
      "get_length = null\r\n",
      "\r\n",
      "[training.batcher.size]\r\n",
      "@schedules = \"compounding.v1\"\r\n",
      "start = 100\r\n",
      "stop = 1000\r\n",
      "compound = 1.001\r\n",
      "t = 0.0\r\n",
      "\r\n",
      "[training.logger]\r\n",
      "@loggers = \"spacy.ConsoleLogger.v1\"\r\n",
      "progress_bar = false\r\n",
      "\r\n",
      "[training.optimizer]\r\n",
      "@optimizers = \"Adam.v1\"\r\n",
      "beta1 = 0.9\r\n",
      "beta2 = 0.999\r\n",
      "L2_is_weight_decay = true\r\n",
      "L2 = 0.01\r\n",
      "grad_clip = 1.0\r\n",
      "use_averages = false\r\n",
      "eps = 0.00000001\r\n",
      "learn_rate = 0.001\r\n",
      "\r\n",
      "[training.score_weights]\r\n",
      "pos_acc = 0.5\r\n",
      "morph_acc = 0.5\r\n",
      "morph_per_feat = null\r\n",
      "\r\n",
      "[pretraining]\r\n",
      "\r\n",
      "[initialize]\r\n",
      "vectors = ${paths.vectors}\r\n",
      "init_tok2vec = ${paths.init_tok2vec}\r\n",
      "vocab_data = null\r\n",
      "lookups = null\r\n",
      "before_init = null\r\n",
      "after_init = null\r\n",
      "\r\n",
      "[initialize.components]\r\n",
      "\r\n",
      "[initialize.tokenizer]"
     ]
    }
   ],
   "source": [
    "!cat ./config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ad1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-12-13 06:33:24,841] [INFO] Set up nlp object from config\n",
      "[2021-12-13 06:33:24,854] [INFO] Pipeline: ['tok2vec', 'morphologizer']\n",
      "[2021-12-13 06:33:24,859] [INFO] Created vocabulary\n",
      "[2021-12-13 06:33:24,859] [INFO] Finished initializing nlp object\n",
      "[2021-12-13 06:33:26,350] [INFO] Initialized pipeline components: ['tok2vec', 'morphologizer']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'morphologizer']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS MORPH...  POS_ACC  MORPH_ACC  SCORE \n",
      "---  ------  ------------  -------------  -------  ---------  ------\n",
      "  0       0          0.00         344.92    38.65      32.42    0.36\n",
      "  3     200        559.91       20735.52    86.16      84.75    0.85\n",
      "  6     400        410.96        3760.20    86.73      85.18    0.86\n",
      "  9     600        291.78        1731.70    86.72      85.74    0.86\n",
      " 12     800        249.35        1114.30    87.04      85.49    0.86\n",
      " 15    1000        191.11         689.11    86.60      85.32    0.86\n",
      " 18    1200        183.42         540.15    86.47      85.22    0.86\n",
      " 21    1400        174.19         454.09    86.60      85.54    0.86\n",
      " 24    1600        167.34         383.80    86.97      85.88    0.86\n",
      " 27    1800        161.70         346.21    87.04      85.79    0.86\n",
      " 30    2000        169.24         336.30    86.59      85.63    0.86\n",
      " 33    2200        179.28         324.36    86.63      85.48    0.86\n",
      " 36    2400        166.33         283.29    86.82      85.48    0.86\n",
      " 39    2600        146.95         240.17    86.96      85.63    0.86\n",
      " 42    2800        179.48         263.65    86.85      85.77    0.86\n",
      " 45    3000        145.96         208.41    86.84      85.86    0.86\n",
      " 48    3200        160.57         218.73    86.89      85.74    0.86\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ./config.cfg --output ./output --paths.train ./corpus/train.spacy --paths.dev ./corpus/dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2134b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Building package artifacts: sdist\u001b[0m\n",
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "output/model-best/meta.json\n",
      "\u001b[38;5;2m✔ Generated README.md from meta.json\u001b[0m\n",
      "\u001b[38;5;2m✔ Successfully created package 'pt_my_pipeline_morphologizer-1.0.0'\u001b[0m\n",
      "packages/pt_my_pipeline_morphologizer-1.0.0\n",
      "running sdist\n",
      "running egg_info\n",
      "creating pt_my_pipeline_morphologizer.egg-info\n",
      "writing pt_my_pipeline_morphologizer.egg-info/PKG-INFO\n",
      "writing dependency_links to pt_my_pipeline_morphologizer.egg-info/dependency_links.txt\n",
      "writing entry points to pt_my_pipeline_morphologizer.egg-info/entry_points.txt\n",
      "writing requirements to pt_my_pipeline_morphologizer.egg-info/requires.txt\n",
      "writing top-level names to pt_my_pipeline_morphologizer.egg-info/top_level.txt\n",
      "writing manifest file 'pt_my_pipeline_morphologizer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'pt_my_pipeline_morphologizer.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "warning: no files found matching 'LICENSE'\n",
      "warning: no files found matching 'LICENSES_SOURCES'\n",
      "writing manifest file 'pt_my_pipeline_morphologizer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating pt_my_pipeline_morphologizer-1.0.0\n",
      "creating pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer\n",
      "creating pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "creating pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0\n",
      "creating pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/morphologizer\n",
      "creating pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/tok2vec\n",
      "creating pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab\n",
      "copying files to pt_my_pipeline_morphologizer-1.0.0...\n",
      "copying MANIFEST.in -> pt_my_pipeline_morphologizer-1.0.0\n",
      "copying README.md -> pt_my_pipeline_morphologizer-1.0.0\n",
      "copying meta.json -> pt_my_pipeline_morphologizer-1.0.0\n",
      "copying setup.py -> pt_my_pipeline_morphologizer-1.0.0\n",
      "copying pt_my_pipeline_morphologizer/__init__.py -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer\n",
      "copying pt_my_pipeline_morphologizer/meta.json -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer\n",
      "copying pt_my_pipeline_morphologizer.egg-info/PKG-INFO -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer.egg-info/SOURCES.txt -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer.egg-info/dependency_links.txt -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer.egg-info/entry_points.txt -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer.egg-info/not-zip-safe -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer.egg-info/requires.txt -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer.egg-info/top_level.txt -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer.egg-info\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/README.md -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/config.cfg -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/meta.json -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/tokenizer -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/morphologizer/cfg -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/morphologizer\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/morphologizer/model -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/morphologizer\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/tok2vec/cfg -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/tok2vec\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/tok2vec/model -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/tok2vec\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab/key2row -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab/lookups.bin -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab/strings.json -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab\n",
      "copying pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab/vectors -> pt_my_pipeline_morphologizer-1.0.0/pt_my_pipeline_morphologizer/pt_my_pipeline_morphologizer-1.0.0/vocab\n",
      "Writing pt_my_pipeline_morphologizer-1.0.0/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'pt_my_pipeline_morphologizer-1.0.0' (and everything under it)\n",
      "\u001b[38;5;2m✔ Successfully created zipped Python package\u001b[0m\n",
      "packages/pt_my_pipeline_morphologizer-1.0.0/dist/pt_my_pipeline_morphologizer-1.0.0.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy package ./output/model-best ./packages --name my_pipeline_morphologizer --version 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7692f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"packages/pt_my_pipeline_morphologizer-1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a749c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jessi/Documentos/Data_Science/spacy/model_pos/packages/pt_my_pipeline_morphologizer-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc8896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "Processing ./dist/pt_my_pipeline_morphologizer-1.0.0.tar.gz\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.3 in /home/jessi/anaconda3/lib/python3.8/site-packages (from pt-my-pipeline-morphologizer==1.0.0) (3.1.3)\n",
      "Requirement already satisfied: jinja2 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (59.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (0.3.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (0.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (8.0.13)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (4.62.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (1.21.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (1.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (20.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/jessi/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (5.1.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/jessi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jessi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jessi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jessi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/jessi/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jessi/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.3->pt-my-pipeline-morphologizer==1.0.0) (2.0.1)\n",
      "Building wheels for collected packages: pt-my-pipeline-morphologizer\n",
      "  Building wheel for pt-my-pipeline-morphologizer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pt-my-pipeline-morphologizer: filename=pt_my_pipeline_morphologizer-1.0.0-py3-none-any.whl size=6179012 sha256=df45b46afba45f91bdc33169b7a5497a2d682f9745136bb7d373cc13143de18a\n",
      "  Stored in directory: /home/jessi/.cache/pip/wheels/4f/17/e6/bd00b77bfb6dcc970b68e14672aae4f810e90d11c4867bfba3\n",
      "Successfully built pt-my-pipeline-morphologizer\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "Installing collected packages: pt-my-pipeline-morphologizer\n",
      "  Attempting uninstall: pt-my-pipeline-morphologizer\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: pt-my-pipeline-morphologizer 1.0.0\n",
      "    Uninstalling pt-my-pipeline-morphologizer-1.0.0:\n",
      "      Successfully uninstalled pt-my-pipeline-morphologizer-1.0.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "Successfully installed pt-my-pipeline-morphologizer-1.0.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/jessi/anaconda3/lib/python3.8/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dist/pt_my_pipeline_morphologizer-1.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbb8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download pt_core_news_sm\n",
    "#!python -m spacy download pt_core_news_md\n",
    "#!python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d48caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um de os fatores que determina a qualidade de o gasolina pirolisada e de suas frações de destilação e hidrogenação em o indústria de petróleo é o teor de dienos conjugados, assim como o de o olefinas, de compostos aromáticos e ramificados.\n",
      "\n",
      "MODELO SMALL PARA PORTUGUÉS\n",
      "[('Um', 'NUM'), ('de', 'ADP'), ('os', 'DET'), ('fatores', 'NOUN'), ('que', 'PRON'), ('determina', 'VERB'), ('a', 'DET'), ('qualidade', 'NOUN'), ('de', 'ADP'), ('o', 'DET'), ('gasolina', 'NOUN'), ('pirolisada', 'VERB'), ('e', 'CCONJ'), ('de', 'ADP'), ('suas', 'DET'), ('frações', 'NOUN'), ('de', 'ADP'), ('destilação', 'NOUN'), ('e', 'CCONJ'), ('hidrogenação', 'NOUN'), ('em', 'ADP'), ('o', 'DET'), ('indústria', 'NOUN'), ('de', 'ADP'), ('petróleo', 'NOUN'), ('é', 'AUX'), ('o', 'DET'), ('teor', 'NOUN'), ('de', 'ADP'), ('dienos', 'NOUN'), ('conjugados', 'VERB'), (',', 'PUNCT'), ('assim', 'ADV'), ('como', 'ADP'), ('o', 'PRON'), ('de', 'ADP'), ('o', 'DET'), ('olefinas', 'NOUN'), (',', 'PUNCT'), ('de', 'ADP'), ('compostos', 'NOUN'), ('aromáticos', 'ADJ'), ('e', 'CCONJ'), ('ramificados', 'VERB'), ('.', 'PUNCT')]\n",
      "96\n",
      "\n",
      "MODELO MÉDIO PARA PORTUGUÉS\n",
      "[('Um', 'NUM'), ('de', 'ADP'), ('os', 'DET'), ('fatores', 'NOUN'), ('que', 'PRON'), ('determina', 'VERB'), ('a', 'DET'), ('qualidade', 'NOUN'), ('de', 'ADP'), ('o', 'DET'), ('gasolina', 'NOUN'), ('pirolisada', 'VERB'), ('e', 'CCONJ'), ('de', 'ADP'), ('suas', 'DET'), ('frações', 'NOUN'), ('de', 'ADP'), ('destilação', 'NOUN'), ('e', 'CCONJ'), ('hidrogenação', 'NOUN'), ('em', 'ADP'), ('o', 'DET'), ('indústria', 'NOUN'), ('de', 'ADP'), ('petróleo', 'NOUN'), ('é', 'AUX'), ('o', 'DET'), ('teor', 'NOUN'), ('de', 'ADP'), ('dienos', 'ADJ'), ('conjugados', 'VERB'), (',', 'PUNCT'), ('assim', 'ADV'), ('como', 'ADP'), ('o', 'PRON'), ('de', 'ADP'), ('o', 'DET'), ('olefinas', 'NOUN'), (',', 'PUNCT'), ('de', 'ADP'), ('compostos', 'NOUN'), ('aromáticos', 'ADJ'), ('e', 'CCONJ'), ('ramificados', 'VERB'), ('.', 'PUNCT')]\n",
      "300\n",
      "\n",
      "MODELO LARGE PARA PORTUGUÉS\n",
      "[('Um', 'NUM'), ('de', 'ADP'), ('os', 'DET'), ('fatores', 'NOUN'), ('que', 'PRON'), ('determina', 'VERB'), ('a', 'DET'), ('qualidade', 'NOUN'), ('de', 'ADP'), ('o', 'DET'), ('gasolina', 'NOUN'), ('pirolisada', 'ADJ'), ('e', 'CCONJ'), ('de', 'ADP'), ('suas', 'DET'), ('frações', 'NOUN'), ('de', 'ADP'), ('destilação', 'NOUN'), ('e', 'CCONJ'), ('hidrogenação', 'NOUN'), ('em', 'ADP'), ('o', 'DET'), ('indústria', 'NOUN'), ('de', 'ADP'), ('petróleo', 'NOUN'), ('é', 'AUX'), ('o', 'DET'), ('teor', 'NOUN'), ('de', 'ADP'), ('dienos', 'ADJ'), ('conjugados', 'VERB'), (',', 'PUNCT'), ('assim', 'ADV'), ('como', 'ADP'), ('o', 'PRON'), ('de', 'ADP'), ('o', 'DET'), ('olefinas', 'NOUN'), (',', 'PUNCT'), ('de', 'ADP'), ('compostos', 'NOUN'), ('aromáticos', 'ADJ'), ('e', 'CCONJ'), ('ramificados', 'VERB'), ('.', 'PUNCT')]\n",
      "300\n",
      "\n",
      "MODELO CREADO\n",
      "[('Um', 'PRON'), ('de', 'ADP'), ('os', 'DET'), ('fatores', 'NOUN'), ('que', 'PRON'), ('determina', 'VERB'), ('a', 'DET'), ('qualidade', 'NOUN'), ('de', 'ADP'), ('o', 'DET'), ('gasolina', 'NOUN'), ('pirolisada', 'VERB'), ('e', 'CCONJ'), ('de', 'ADP'), ('suas', 'DET'), ('frações', 'NOUN'), ('de', 'ADP'), ('destilação', 'NOUN'), ('e', 'CCONJ'), ('hidrogenação', 'NOUN'), ('em', 'ADP'), ('o', 'DET'), ('indústria', 'NOUN'), ('de', 'ADP'), ('petróleo', 'NOUN'), ('é', 'AUX'), ('o', 'DET'), ('teor', 'NOUN'), ('de', 'ADP'), ('dienos', 'NOUN'), ('conjugados', 'ADJ'), (',', 'PUNCT'), ('assim', 'ADV'), ('como', 'ADP'), ('o', 'DET'), ('de', 'ADP'), ('o', 'DET'), ('olefinas', 'NOUN'), (',', 'PUNCT'), ('de', 'ADP'), ('compostos', 'NOUN'), ('aromáticos', 'ADJ'), ('e', 'CCONJ'), ('ramificados', 'VERB'), ('.', 'PUNCT')]\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import re\n",
    "\n",
    "nlp_sm = spacy.load(\"pt_core_news_sm\")\n",
    "nlp_md = spacy.load(\"pt_core_news_md\")\n",
    "nlp_lg = spacy.load(\"pt_core_news_lg\")\n",
    "nlp = spacy.load(\"pt_my_pipeline_morphologizer\")\n",
    "\n",
    "text = \"Um dos fatores que determina a qualidade da gasolina pirolisada e de suas frações de destilação e \"\\\n",
    "\"hidrogenação na indústria de petróleo é o teor de dienos conjugados, assim como o das olefinas, \"\\\n",
    "\"de compostos aromáticos e ramificados.\" \n",
    "\n",
    "dic = {\"dos\": \"de os\", \"da\": \"de o\", \"na\": \"em o\", \"das\": \"de o\"}\n",
    "\n",
    "for k, v in dic.items():\n",
    "    text = re.sub(rf\"\\b{k}\\b\", v, text)            \n",
    "    \n",
    "print(text, end = \"\\n\\n\")    \n",
    "\n",
    "print(\"MODELO SMALL PARA PORTUGUÉS\")\n",
    "doc = nlp_sm(text)    \n",
    "print([(token.text, token.pos_) for token in doc])\n",
    "print(len(doc[2].vector))\n",
    "\n",
    "print(\"\\nMODELO MÉDIO PARA PORTUGUÉS\")\n",
    "doc = nlp_md(text)    \n",
    "print([(token.text, token.pos_) for token in doc])\n",
    "print(len(doc[2].vector))\n",
    "\n",
    "print(\"\\nMODELO LARGE PARA PORTUGUÉS\")\n",
    "doc = nlp_lg(text)    \n",
    "print([(token.text, token.pos_) for token in doc])\n",
    "print(len(doc[2].vector))\n",
    "\n",
    "print(\"\\nMODELO CREADO\")\n",
    "doc = nlp(text)\n",
    "print([(token.text, token.pos_) for token in doc])\n",
    "print(len(doc[2].vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819e1c6",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "- https://prodi.gy/\n",
    "- https://www.rubrix.ml/\n",
    "- https://docs.rubrix.ml/en/stable/\n",
    "- https://spacy.io/usage/training#quickstart\n",
    "- https://spacy.io/usage/training#config\n",
    "- https://spacy.io/usage/training#config-custom\n",
    "- https://spacy.io/api/morphologizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bae29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
